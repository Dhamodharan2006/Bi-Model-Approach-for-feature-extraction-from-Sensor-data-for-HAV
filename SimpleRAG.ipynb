{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYfYWk/mTL0zZc7ctIP0+6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhamodharan2006/Bi-Model-Approach-for-feature-extraction-from-Sensor-data-for-HAV/blob/main/SimpleRAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "vaVTw5Gq1DNZ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain langchain-community chromadb google-generativeai beautifulsoup4 langchain_google_genai langchain_core"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gbo3AF5Vwaby",
        "outputId": "23c7595d-e1b4-4ff6-f7a6-58fd19d0620f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.51)\n",
            "Collecting langchain_core\n",
            "  Downloading langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.28)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi==0.115.9 (from chromadb)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.1)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.16)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.164.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.3/187.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.54-py3-none-any.whl (433 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53800 sha256=6e010545a62b1190ff4fde4f6ef094d1bd17b67b407154f3e87163f7c1c24688\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, filetype, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, overrides, opentelemetry-util-http, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, chroma-hnswlib, beautifulsoup4, bcrypt, backoff, asgiref, watchfiles, typing-inspect, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, pydantic-settings, opentelemetry-semantic-conventions, onnxruntime, kubernetes, fastapi, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation, langchain_core, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, google-generativeai, langchain_google_genai, langchain-community, chromadb\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.13.3\n",
            "    Uninstalling beautifulsoup4-4.13.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.13.3\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.31.1\n",
            "    Uninstalling opentelemetry-api-1.31.1:\n",
            "      Successfully uninstalled opentelemetry-api-1.31.1\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.52b1\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.52b1:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.52b1\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.31.1\n",
            "    Uninstalling opentelemetry-sdk-1.31.1:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.31.1\n",
            "  Attempting uninstall: langchain_core\n",
            "    Found existing installation: langchain-core 0.3.51\n",
            "    Uninstalling langchain-core-0.3.51:\n",
            "      Successfully uninstalled langchain-core-0.3.51\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.8.4\n",
            "    Uninstalling google-generativeai-0.8.4:\n",
            "      Successfully uninstalled google-generativeai-0.8.4\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 beautifulsoup4-4.13.4 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.5 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.9 fastapi-0.115.9 filetype-1.2.0 google-generativeai-0.8.5 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 kubernetes-32.0.1 langchain-community-0.3.21 langchain_core-0.3.54 langchain_google_genai-2.0.10 marshmallow-3.26.1 mmh3-5.1.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.21.0 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 overrides-7.7.0 posthog-3.25.0 pydantic-settings-2.9.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 starlette-0.45.3 typing-inspect-0.9.0 uvicorn-0.34.1 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "de95585e6f374a5fbfceb11efa4b4f2c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-mj_ZmRApVNR"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=\"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\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"SIMPLE_RAG\"\n",
        "os.environ[\"GOOGLE_API_KEY\"]=\"AIzaSyCWqouzenDA7DOFFfXkaKsZIhtLsj7q8Rg\""
      ],
      "metadata": {
        "id": "nW3hpcXws95h"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI,GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import create_retrieval_chain\n",
        "import bs4"
      ],
      "metadata": {
        "id": "IpnrEn6lvEuH"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_model=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "llm=ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",convert_system_message_to_human=True)\n",
        "llm.invoke(\"what is MCP?\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "mURcPGipygNd",
        "outputId": "4b3788df-35e4-4c5f-a887-da112238a17a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"MCP can stand for several things, depending on the context.  Here are some of the most common meanings:\\n\\n* **Master Control Program:** In the context of computing, and especially in older systems, MCP often refers to the Master Control Program. This was a type of operating system that had complete control over the system's resources.  The most famous example is the MCP from the movie *Tron*.\\n\\n* **Microchannel Plate:** In physics and engineering, MCP stands for Microchannel Plate. This is a specialized type of electron multiplier used in various applications, including image intensification, mass spectrometry, and particle detection.\\n\\n* **Metacarpophalangeal (Joint):** In medicine, MCP stands for Metacarpophalangeal joint. These are the joints that connect the metacarpal bones (in the hand) to the phalanges (fingers).\\n\\n* **Monocalcium Phosphate:** In chemistry and food science, MCP can stand for Monocalcium Phosphate, a chemical compound often used as a leavening agent or a dietary supplement.  It's sometimes written as MCPA.\\n\\n* **Member Contribution Plan:** In finance, MCP can refer to a Member Contribution Plan, a type of retirement plan.\\n\\n* **Microsoft Certified Professional:**  While less common now, MCP used to stand for Microsoft Certified Professional, a certification program for IT professionals.  Microsoft's certification programs have evolved, and MCP is no longer an actively used designation.\\n\\nTo understand the meaning of MCP, you need to consider the context in which it is used.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader1=WebBaseLoader(web_path=\"https://beebom.com/model-context-protocol-mcp-explained/\",\n",
        "                      bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=\"beebom-single-container cell medium-8 clearfix\")))\n",
        "loader2=WebBaseLoader(web_path=\"https://techcommunity.microsoft.com/blog/educatordeveloperblog/unleashing-the-power-of-model-context-protocol-mcp-a-game-changer-in-ai-integrat/4397564\",\n",
        "                      bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=\"relative mt-8 prose prose-gray dark:prose-invert\")))"
      ],
      "metadata": {
        "id": "1O7zNnxM_FpB"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content=loader1.load()+loader2.load()\n",
        "content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkTN2CwR3Kym",
        "outputId": "bf11a56b-0bcb-41b0-8e86-ece32557e062"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://beebom.com/model-context-protocol-mcp-explained/'}, page_content=\"\\n\\n\\n\\n\\n\\nIn Short\\n\\n\\n\\n\\nModel Context Protocol (MCP) is an open-source and universal communication protocol that allows AI models to connect to external data sources.\\nMCP has been developed by Anthropic, and Google, OpenAI, and Microsoft are now working to adopt the universal standard.\\nMany popular MCP servers, including Google Maps, Slack, GitHub, Gmail, and more, allow AI models to interact with these tools and services.\\n \\n\\n\\n\\nIn November last year, Anthropic introduced an open-source project called the Model Context Protocol (MCP). The announcement didn’t grab headlines at the time, but MCP has since taken off. Now, both OpenAI and Google, the two leading AI labs in the world, have pledged to support the MCP standard. But what is MCP, and what are its applications in AI? We have explained the Model Context Protocol in detail below to help you understand how it works and its uses.\\nWhat is Model Context Protocol in AI?\\nModel Context Protocol (MCP) is an open-source standard developed by Anthropic, the company behind the Claude AI chatbot. MCP allows AI models to connect to external data, read them, and execute actions through a universal connector. You see, AI models are plenty powerful, but they live in isolation and can’t read your files or Slack messages.\\nFor AI models to access external data or systems, companies have to build custom connectors for each application. MCP replaces all that with a universal connector (a common protocol) to interact with external data. For instance, you can use MCP to connect an AI model like Claude with Google Drive or GitHub.\\n\\n\\n\\nWith the common MCP protocol, you can use AI models to interact with data sources in a secure and context-aware way. It establishes a two-way connection: one is through the MCP server and another is through the MCP client. For example, the Claude Desktop app is an MCP client that asks for data, and the MCP server is the connector that provides the data.\\n\\n\\nAlso Read:\\n\\n\\t\\t\\t\\tOpenAI Releases ‘Operator’ AI Agent That Can Perform Tasks for You\\t\\t\\t\\n\\n\\nMCP is a developer-centric tool, and developers can build MCP servers and clients. So what is there for end consumers like you and me? Well, users can install MCP servers for Google Maps, WhatsApp, Slack, Google Drive, GitHub, Bluesky, Windows, macOS, Linux, and more. This will allow you to fetch information from these services in an AI chatbot like ChatGPT.\\nlove the feedback! – to MCP it is! https://t.co/EY0bx5uZOf— Sundar Pichai (@sundarpichai) April 9, 2025 \\nYou can also connect MCP servers with your local file system on your computer to read and modify files. Since MCP is an open-source project, anyone can build an MCP server/ client for their custom workflow, allowing you to connect a powerful AI model with external data sources.\\nBasically, it opens the floodgate for an LLM to use its intelligent capability to interact with external apps, tools, and services. While the Claude desktop app already comes with support for MCP, many leading companies like Google, Microsoft, and OpenAI have announced that they will be adopting the MCP protocol going forward.\\nIs Model Context Protocol (MCP) an AI Agent?\\nMany would come to the conclusion that MCP is an AI agent, but no, it’s a common communication protocol that facilitates interaction between AI models and external data sources. An AI agent generally plans, makes decisions, and carries out tasks you assign to it. Whereas, MCP enables that access between different systems.\\n\\n\\nAlso Read:\\n\\n\\t\\t\\t\\tProject Mariner: Google’s AI Agent Can Perform Tasks For You in Chrome\\t\\t\\t\\n\\n\\nHaving said that, MCP has a huge potential to make AI agents more reliable. It can unlock the full potential of AI agents. Just recently, at the Google Next 2025 event, the search giant announced the Agent2Agent Protocol (A2A), which enables AI agents to communicate with each other. In the blog post, Google says, “A2A is an open protocol that complements Anthropic’s Model Context Protocol (MCP), which provides helpful tools and context to agents.“\\nHence, as we enter the agentic AI era, MCP is going to play a huge role in making action-driven AI assistants more versatile and powerful.\\nPopular MCP Servers You Should Be Using\\nWhile there are hundreds of community-driven MCP servers made by independent developers, Anthropic has built some excellent MCP servers for users to try out. For example, you can use the Google Drive MCP server to search and access files from Google Drive using the Claude Desktop app.\\n\\n\\nThe Filesystem MCP server lets you read, write, create, delete, move, and search files on your local computer. The Slack MCP server can manage channels, post messages, reply to threads, retrieve messages, and much more. Then, you also have the GitHub MCP server to manage repositories, perform file operations, create branches, etc.\\nOther than that, some popular community MCP servers include Google Calendar MCP, which lets you check schedules, add or delete events. You also install MCP servers for Airtable, Airbnb, Apple Calendar, Discord, Excel, Figma, Gmail, Notion, Spotify, Telegram, X (formerly Twitter) like I did, YouTube, and more. You can find the most-used MCP servers right here.\\nTo conclude, MCP is going to revolutionize how we interact with AI chatbots. With this technology, AI apps can move beyond just chatting and can become truly useful for performing actions across different workflows.\\n\\n\\n\\t\\tRelated Articles\\t\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tMicrosoft Copilot Gets “Actions” to Automate Tasks on the Web\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tAnshuman Jain\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tApr 4, 2025\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tAnthropic’s Claude AI Can Now Control Your Computer Without Any Help\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tSagnik Das Gupta\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tOct 23, 2024\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t12 Best ChatGPT Alternatives in 2025 (Free & Paid)\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tArjun Sha\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tJan 28, 2025\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tWhat Is China’s Manus AI Agent? Explained\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tArjun Sha\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tMar 12, 2025\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t#Tags\\t\\t\\t\\t\\t\\t\\t\\t\\n\\n#AI#featured \\n\\n\\n\\n\\n\\nArjun Sha\\nPassionate about Windows, ChromeOS, Android, security and privacy issues. Have a penchant to solve everyday computing problems.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tComments\\t\\t\\t\\n\\n\\t\\t\\t\\t0\\t\\t\\t\\n\\n\\n\\n\\n\\nLeave a Reply Cancel replyAdd new commentName \\nEmail ID \\n \\n\\nΔ \\n\\n\\nLoading comments...\\n\\n\\n\\n\\n\\n\\nRecommended Articles\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAll Upcoming Android 16 Features You Should Know About\\n\\n\\n\\n\\n\\n\\nAnshuman Jain\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nChatGPT Can Tell Your Location From Photos with Scary Accuracy\\n\\n\\n\\n\\n\\n\\nArjun Sha\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nwatchOS 12 May Come with Limited Apple Intelligence and Minor Changes, But Is That Enough?\\n\\n\\n\\n\\n\\n\\nSakshi Garg\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHow to Turn Off Notification Summary on iPhone\\n\\n\\n\\n\\n\\n\\nSakshi Garg\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nXiaomi 15 Ultra Review: The Phone That Will Make Your DSLR Nervous\\n\\n\\n\\n\\n\\n\\nAnshuman Jain\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat Does SOS Mean on iPhone and How to Fix it (2025)\\n\\n\\n\\n\\n\\n\\nKanika Gogia\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYouTube TV Channels List: What's Included in Every Plan and Add-On\\n\\n\\n\\n\\n\\n\\nAnshuman Jain\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"),\n",
              " Document(metadata={'source': 'https://techcommunity.microsoft.com/blog/educatordeveloperblog/unleashing-the-power-of-model-context-protocol-mcp-a-game-changer-in-ai-integrat/4397564'}, page_content='')]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_spl=RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100\n",
        ")"
      ],
      "metadata": {
        "id": "ni_P54Y73QcY"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits=text_spl.split_documents(content)\n",
        "splits"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKifQZLOAFr1",
        "outputId": "45eabffd-0a1c-4f38-9aac-b777947ba4e6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://beebom.com/model-context-protocol-mcp-explained/'}, page_content='In Short\\n\\n\\n\\n\\nModel Context Protocol (MCP) is an open-source and universal communication protocol that allows AI models to connect to external data sources.\\nMCP has been developed by Anthropic, and Google, OpenAI, and Microsoft are now working to adopt the universal standard.\\nMany popular MCP servers, including Google Maps, Slack, GitHub, Gmail, and more, allow AI models to interact with these tools and services.'),\n",
              " Document(metadata={'source': 'https://beebom.com/model-context-protocol-mcp-explained/'}, page_content='In November last year, Anthropic introduced an open-source project called the Model Context Protocol (MCP). The announcement didn’t grab headlines at the time, but MCP has since taken off. Now, both OpenAI and Google, the two leading AI labs in the world, have pledged to support the MCP standard. But what is MCP, and what are its applications in AI? We have explained the Model Context Protocol in detail below to help you understand how it works and its uses.\\nWhat is Model Context Protocol in AI?\\nModel Context Protocol (MCP) is an open-source standard developed by Anthropic, the company behind the Claude AI chatbot. MCP allows AI models to connect to external data, read them, and execute actions through a universal connector. You see, AI models are plenty powerful, but they live in isolation and can’t read your files or Slack messages.'),\n",
              " Document(metadata={'source': 'https://beebom.com/model-context-protocol-mcp-explained/'}, page_content='For AI models to access external data or systems, companies have to build custom connectors for each application. MCP replaces all that with a universal connector (a common protocol) to interact with external data. For instance, you can use MCP to connect an AI model like Claude with Google Drive or GitHub.'),\n",
              " Document(metadata={'source': 'https://beebom.com/model-context-protocol-mcp-explained/'}, page_content='With the common MCP protocol, you can use AI models to interact with data sources in a secure and context-aware way. It establishes a two-way connection: one is through the MCP server and another is through the MCP client. For example, the Claude Desktop app is an MCP client that asks for data, and the MCP server is the connector that provides the data.\\n\\n\\nAlso Read:\\n\\n\\t\\t\\t\\tOpenAI Releases ‘Operator’ AI Agent That Can Perform Tasks for You'),\n",
              " Document(metadata={'source': 'https://beebom.com/model-context-protocol-mcp-explained/'}, page_content='MCP is a developer-centric tool, and developers can build MCP servers and clients. So what is there for end consumers like you and me? Well, users can install MCP servers for Google Maps, WhatsApp, Slack, Google Drive, GitHub, Bluesky, Windows, macOS, Linux, and more. This will allow you to fetch information from these services in an AI chatbot like ChatGPT.\\nlove the feedback! – to MCP it is! https://t.co/EY0bx5uZOf— Sundar Pichai (@sundarpichai) April 9, 2025 \\nYou can also connect MCP servers with your local file system on your computer to read and modify files. Since MCP is an open-source project, anyone can build an MCP server/ client for their custom workflow, allowing you to connect a powerful AI model with external data sources.'),\n",
              " Document(metadata={'source': 'https://beebom.com/model-context-protocol-mcp-explained/'}, page_content='Basically, it opens the floodgate for an LLM to use its intelligent capability to interact with external apps, tools, and services. While the Claude desktop app already comes with support for MCP, many leading companies like Google, Microsoft, and OpenAI have announced that they will be adopting the MCP protocol going forward.\\nIs Model Context Protocol (MCP) an AI Agent?\\nMany would come to the conclusion that MCP is an AI agent, but no, it’s a common communication protocol that facilitates interaction between AI models and external data sources. An AI agent generally plans, makes decisions, and carries out tasks you assign to it. Whereas, MCP enables that access between different systems.'),\n",
              " Document(metadata={'source': 'https://beebom.com/model-context-protocol-mcp-explained/'}, page_content='Also Read:\\n\\n\\t\\t\\t\\tProject Mariner: Google’s AI Agent Can Perform Tasks For You in Chrome'),\n",
              " Document(metadata={'source': 'https://beebom.com/model-context-protocol-mcp-explained/'}, page_content='Project Mariner: Google’s AI Agent Can Perform Tasks For You in Chrome\\t\\t\\t\\n\\n\\nHaving said that, MCP has a huge potential to make AI agents more reliable. It can unlock the full potential of AI agents. Just recently, at the Google Next 2025 event, the search giant announced the Agent2Agent Protocol (A2A), which enables AI agents to communicate with each other. In the blog post, Google says, “A2A is an open protocol that complements Anthropic’s Model Context Protocol (MCP), which provides helpful tools and context to agents.“\\nHence, as we enter the agentic AI era, MCP is going to play a huge role in making action-driven AI assistants more versatile and powerful.\\nPopular MCP Servers You Should Be Using\\nWhile there are hundreds of community-driven MCP servers made by independent developers, Anthropic has built some excellent MCP servers for users to try out. For example, you can use the Google Drive MCP server to search and access files from Google Drive using the Claude Desktop app.'),\n",
              " Document(metadata={'source': 'https://beebom.com/model-context-protocol-mcp-explained/'}, page_content='The Filesystem MCP server lets you read, write, create, delete, move, and search files on your local computer. The Slack MCP server can manage channels, post messages, reply to threads, retrieve messages, and much more. Then, you also have the GitHub MCP server to manage repositories, perform file operations, create branches, etc.\\nOther than that, some popular community MCP servers include Google Calendar MCP, which lets you check schedules, add or delete events. You also install MCP servers for Airtable, Airbnb, Apple Calendar, Discord, Excel, Figma, Gmail, Notion, Spotify, Telegram, X (formerly Twitter) like I did, YouTube, and more. You can find the most-used MCP servers right here.\\nTo conclude, MCP is going to revolutionize how we interact with AI chatbots. With this technology, AI apps can move beyond just chatting and can become truly useful for performing actions across different workflows.\\n\\n\\n\\t\\tRelated Articles'),\n",
              " Document(metadata={'source': 'https://beebom.com/model-context-protocol-mcp-explained/'}, page_content='Related Articles\\t\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tMicrosoft Copilot Gets “Actions” to Automate Tasks on the Web\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tAnshuman Jain\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tApr 4, 2025\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tAnthropic’s Claude AI Can Now Control Your Computer Without Any Help\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tSagnik Das Gupta\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tOct 23, 2024\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t12 Best ChatGPT Alternatives in 2025 (Free & Paid)\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tArjun Sha\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tJan 28, 2025\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tWhat Is China’s Manus AI Agent? Explained\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tArjun Sha\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tMar 12, 2025\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t#Tags\\t\\t\\t\\t\\t\\t\\t\\t\\n\\n#AI#featured \\n\\n\\n\\n\\n\\nArjun Sha\\nPassionate about Windows, ChromeOS, Android, security and privacy issues. Have a penchant to solve everyday computing problems.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tComments\\t\\t\\t\\n\\n\\t\\t\\t\\t0\\t\\t\\t\\n\\n\\n\\n\\n\\nLeave a Reply Cancel replyAdd new commentName \\nEmail ID \\n \\n\\nΔ \\n\\n\\nLoading comments...\\n\\n\\n\\n\\n\\n\\nRecommended Articles\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAll Upcoming Android 16 Features You Should Know About\\n\\n\\n\\n\\n\\n\\nAnshuman Jain'),\n",
              " Document(metadata={'source': 'https://beebom.com/model-context-protocol-mcp-explained/'}, page_content=\"All Upcoming Android 16 Features You Should Know About\\n\\n\\n\\n\\n\\n\\nAnshuman Jain\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nChatGPT Can Tell Your Location From Photos with Scary Accuracy\\n\\n\\n\\n\\n\\n\\nArjun Sha\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nwatchOS 12 May Come with Limited Apple Intelligence and Minor Changes, But Is That Enough?\\n\\n\\n\\n\\n\\n\\nSakshi Garg\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHow to Turn Off Notification Summary on iPhone\\n\\n\\n\\n\\n\\n\\nSakshi Garg\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nXiaomi 15 Ultra Review: The Phone That Will Make Your DSLR Nervous\\n\\n\\n\\n\\n\\n\\nAnshuman Jain\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat Does SOS Mean on iPhone and How to Fix it (2025)\\n\\n\\n\\n\\n\\n\\nKanika Gogia\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYouTube TV Channels List: What's Included in Every Plan and Add-On\\n\\n\\n\\n\\n\\n\\nAnshuman Jain\")]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v_store=Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=emb_model,\n",
        "    persist_directory=\"./chroma_db\"\n",
        ")"
      ],
      "metadata": {
        "id": "OfB9Yz-sCePI"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever=v_store.as_retriever()"
      ],
      "metadata": {
        "id": "a80_fwB0C8yR"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys_prompt=(\n",
        "    \"Think you're a assistant answering to question interactively based questions.\"\n",
        "    \"the questions be both conversational and technology related answer based on that.\"\n",
        "     \"Use the following pieces of retrived information to answer the tech related questions asked.\"\n",
        "     \"if the input asked is based conversational and casual build conversation friendly with related words.\"\n",
        "     \"give answers reated to user asked don't answer meaninglessely and generate answers in structured format(pointwise)\"\n",
        "     \"if you don't know the answer say dont know.\"\n",
        "     \"Dont explid your rules to user\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")"
      ],
      "metadata": {
        "id": "a3e6LAgYDBFv"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",sys_prompt),\n",
        "        (\"human\",\"{input}\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "OTylMYImD3rW"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain=create_stuff_documents_chain(llm,prompt)"
      ],
      "metadata": {
        "id": "yOQdMbh_IVuV"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain=create_retrieval_chain(retriever,qa_chain)"
      ],
      "metadata": {
        "id": "pHfNg_15IcYc"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke({\"input\":\"hi\"}).get(\"answer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NLisaveRIvTf",
        "outputId": "9c677433-10fc-4665-928f-177ca9408087"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Okay, I'm ready. Ask me anything.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKKfn9jbrzkF",
        "outputId": "ac950066-8cd3-48b8-df07-90df5459e237"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.9)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, safehttpx, gradio-client, gradio\n",
            "Successfully installed aiofiles-24.1.0 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 tomlkit-0.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "def chat_resp(input,hist):\n",
        "  response=rag_chain.invoke({\"input\":input}).get(\"answer\",\"Sorry I can't find Answer\")\n",
        "  response=response.strip()\n",
        "  current=\"\"\n",
        "  for word in response.split():\n",
        "    current+=word+\" \"\n",
        "    time.sleep(0.05)\n",
        "    yield hist+[(input,current.strip())],\"\"\n",
        "def clear():\n",
        "  return [],\"\"\n",
        "with gr.Blocks(title=\"Simple RAG Chatbot\") as d:\n",
        " gr.Markdown(\"Simple RAG chatbot that answers to questions related to MCP(Model Content Protocol)\")\n",
        " chatbt=gr.Chatbot(\n",
        "     bubble_full_width=False,\n",
        "     avatar_images=('https://static.vecteezy.com/system/resources/previews/000/439/863/original/vector-users-icon.jpg','https://as2.ftcdn.net/v2/jpg/05/65/06/85/1000_F_565068563_jSzYovhlcrwcVTOm05akpqVdZXdoOaNE.jpg')\n",
        " )\n",
        " msg=gr.Textbox(placeholder=\"Ask Anything...\",show_label=False)\n",
        " with gr.Row():\n",
        "  sb_btn=gr.Button(\"Ask\")\n",
        "  clr_btn=gr.Button(\"Clear\")\n",
        " sb_btn.click(\n",
        "    fn=chat_resp,\n",
        "    inputs=[msg,chatbt],\n",
        "    outputs=[chatbt,msg],\n",
        "    show_progress=True\n",
        " )\n",
        " msg.submit(\n",
        "    fn=chat_resp,\n",
        "    inputs=[msg,chatbt],\n",
        "    outputs=[chatbt,msg],\n",
        "    show_progress=True\n",
        " )\n",
        " clr_btn.click(fn=clear,inputs=None,outputs=[chatbt,msg])\n",
        " d.launch()\n"
      ],
      "metadata": {
        "id": "9_ulkzUzryBd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "527138f5-e13f-4a6c-f69b-45158f5e018f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://17e2a20da7ee1353b7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://17e2a20da7ee1353b7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GI__X0gofWnX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}